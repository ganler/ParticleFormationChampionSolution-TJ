{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dependency\n",
    "import os\n",
    "import copy\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "import torchvision.models as models\n",
    "from torchvision import transforms\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "from efficientnet_pytorch import EfficientNet\n",
    "\n",
    "import time\n",
    "import random\n",
    "\n",
    "prefix = '/home/wx/work/particle_formation/' #remember to change it!\n",
    "TRAIN_PATH = prefix + 'data/train/'\n",
    "TEST_PATH = prefix + 'data/test/'\n",
    "train_template = '>>> {} === Epoch [{}/{}], Step [{}/{}], Loss: {:.4f}'\n",
    "test_template = '\\n>>> {} === Test Accuracy of the model on the {} test samples: {} %\\n'\n",
    "datamean = 4.924873\n",
    "datastd = 1.877537\n",
    "weight = [0.1631, 0.1557, 0.1598, 0.1731, 0.1708, 0.1776] # PCA-1st\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class dataset\n",
    "class DispersionDataSet(torch.utils.data.Dataset):\n",
    "    def __init__(self, file_path, exp_index, cat=False, combined=False, transform=transforms.ToTensor()):\n",
    "        tmp_df = pd.read_csv(file_path, converters={'image':str})\n",
    "        self.transform = transform\n",
    "        self.data_path = tmp_df['image']\n",
    "        self.exp_index = exp_index\n",
    "        self.cat = cat\n",
    "        self.combined = combined\n",
    "        if exp_index == 0:\n",
    "            if not self.combined:\n",
    "                self.labels = tmp_df['total_rating'].astype(np.float32)\n",
    "            else:\n",
    "                self.labels = tmp_df['total_rating'].astype(np.float32)\n",
    "                self.ypos = tmp_df.loc[:,['r1','r2','r3','r4']].astype(np.float32)\n",
    "        else:\n",
    "            self.labels = tmp_df['exp' + str(exp_index)].astype(np.int32) - 1\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        image = Image.open(TRAIN_PATH + str(self.data_path[index]) + '.bmp' )\n",
    "        if self.cat:\n",
    "            img1 = image.crop((40, 40, 350, 220))\n",
    "            img2 = image.crop((40, 320, 350, 440))\n",
    "            img3 = image.crop((40, 440, 350, 660))\n",
    "            if self.transform is not None:\n",
    "                img1 = self.transform(img1)\n",
    "                img2 = self.transform(img2)\n",
    "                img3 = self.transform(img3)\n",
    "            \n",
    "            imgs = torch.cat([img1, img2, img3], 0)\n",
    "            poss = torch.from_numpy(np.array(self.ypos.iloc[index]))\n",
    "            if self.exp_index == 0:\n",
    "                if self.combined:\n",
    "                    x = torch.cat((imgs.flatten(0), poss.flatten(0)), -1)\n",
    "                    label = torch.from_numpy(np.array(self.labels[index]))\n",
    "                else:\n",
    "                    x = torch.cat([img1, img2, img3], 0)\n",
    "                    label = torch.from_numpy(np.array(self.labels[index]))\n",
    "            else:\n",
    "                x = torch.cat([img1, img2, img3], 0)\n",
    "                label = torch.from_numpy(np.array(self.labels[index])).long()\n",
    "            return x, label    \n",
    "        else:\n",
    "            if self.transform is not None:\n",
    "                x = self.transform(image)\n",
    "            \n",
    "            imgs = self.transform(image)\n",
    "            poss = torch.from_numpy(np.array(self.ypos.iloc[index]))\n",
    "            if self.exp_index == 0:\n",
    "                if self.combined:\n",
    "                    x = torch.cat((imgs.flatten(0), poss.flatten(0)), -1)\n",
    "                    label = torch.from_numpy(np.array(self.labels[index]))\n",
    "                else:\n",
    "                    x = self.transform(image)\n",
    "                    label = torch.from_numpy(np.array(self.labels[index]))\n",
    "            else:\n",
    "                x = self.transform(image)\n",
    "                label = torch.from_numpy(np.array(self.labels[index])).long()\n",
    "            return x, label\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.data_path)\n",
    "\n",
    "class PredictDataSet(torch.utils.data.Dataset):\n",
    "    def __init__(self, file_path, exp_index, cat=False, combined=False, transform=transforms.ToTensor()):\n",
    "        tmp_df = pd.read_csv(file_path, converters={'image':str})\n",
    "        self.transform = transform\n",
    "        self.data_path = tmp_df['image']\n",
    "        self.exp_index = exp_index\n",
    "        self.cat = cat\n",
    "        self.combined = combined\n",
    "        if self.combined:\n",
    "            self.ypos = tmp_df.loc[:,['r1','r2','r3','r4']].astype(np.float32)\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        image = Image.open(TRAIN_PATH + str(self.data_path[index]) + '.bmp' )\n",
    "        if self.cat:\n",
    "            img1 = image.crop((40, 40, 350, 220))\n",
    "            img2 = image.crop((40, 320, 350, 440))\n",
    "            img3 = image.crop((40, 440, 350, 660))\n",
    "            if self.transform is not None:\n",
    "                img1 = self.transform(img1)\n",
    "                img2 = self.transform(img2)\n",
    "                img3 = self.transform(img3)\n",
    "\n",
    "            imgs = torch.cat([img1, img2, img3], 0)\n",
    "            poss = torch.from_numpy(np.array(self.ypos.iloc[index]))\n",
    "            if self.exp_index == 0 and self.combined:\n",
    "                x = torch.cat((imgs.flatten(0), poss.flatten(0)), -1)\n",
    "            else:\n",
    "                x = torch.cat([img1, img2, img3], 0)\n",
    "            return x   \n",
    "        else:\n",
    "            if self.transform is not None:\n",
    "                x = self.transform(image)\n",
    "            imgs = self.transform(image)\n",
    "            poss = torch.from_numpy(np.array(self.ypos.iloc[index]))\n",
    "            if self.exp_index == 0 and self.combined:\n",
    "                x = torch.cat((imgs.flatten(0), poss.flatten(0)), -1)\n",
    "            else:\n",
    "                x = self.transform(image)\n",
    "            return x\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.data_path)      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# networks\n",
    "class navienet(nn.Module):\n",
    "    def __init__(self, num_classes=9):\n",
    "        super(navienet, self).__init__()\n",
    "        self.main_layer = nn.Sequential(\n",
    "            nn.Linear(224 * 224, 1024),\n",
    "            nn.Sigmoid(),\n",
    "            nn.Linear(1024, num_classes)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.main_layer(x.view(x.size(0), -1))\n",
    "\n",
    "class navie_regnet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(navie_regnet, self).__init__()\n",
    "        self.main_layer = nn.Sequential(\n",
    "            nn.Linear(224 * 224, 1024),\n",
    "            nn.Sigmoid(),\n",
    "            nn.Linear(1024, 1)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.main_layer(x.view(x.size(0), -1)).squeeze() * 8\n",
    "\n",
    "class stayup_net(nn.Module):\n",
    "    def __init__(self, res):\n",
    "        super(stayup_net, self).__init__()\n",
    "        self.model = res\n",
    "        self.to(device)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n",
    "    \n",
    "class pc_regressor(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(pc_regressor, self).__init__()\n",
    "        self.main_layer = nn.Sequential(\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "        self.fc = nn.Linear(4, 1)\n",
    "        self.to(device)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.main_layer(self.fc(x)) * 8.0 + 1\n",
    "        return out\n",
    "\n",
    "class exp_wrapper(nn.Module):\n",
    "    def __init__(self, m0, m1, m2, m3, m4, m5):\n",
    "        super(exp_wrapper, self).__init__()\n",
    "        self.modules = [m0, m1, m2, m3, m4, m5]\n",
    "        self.to(device)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        o0 = self.modules[0](x)\n",
    "        o1 = self.modules[1](x)\n",
    "        o2 = self.modules[2](x)\n",
    "        o3 = self.modules[3](x)\n",
    "        o4 = self.modules[4](x)\n",
    "        o5 = self.modules[5](x)\n",
    "        return torch.mean(torch.argmax(torch.stack([o0, o1, o2, o3, o4, o5]), dim=-1).float() + 1.0, dim=0, keepdim=True)\n",
    "\n",
    "class combined_reg(nn.Module):\n",
    "    def __init__(self, num_classes=9, plain_res=False):\n",
    "        super(combined_reg, self).__init__()\n",
    "        self.num_classes = num_classes\n",
    "        self.plain_res = plain_res\n",
    "        self.basics = []\n",
    "        for i in range(6):\n",
    "            if plain_res:\n",
    "                res = models.resnet18(pretrained=True)\n",
    "                res.conv1 = nn.Conv2d(1, 64, kernel_size=7, stride=2, padding=3, bias=False)\n",
    "                res.relu = nn.Sigmoid()\n",
    "                # res.fc = nn.Linear(512, self.num_classes)\n",
    "                self.basics.append(res)\n",
    "            else:\n",
    "                res = models.resnet18(pretrained=True)\n",
    "                res.relu = nn.Sigmoid()\n",
    "                res.fc = nn.Linear(512, self.num_classes)\n",
    "                self.basics.append(stayup_net(res))\n",
    "                self.basics[i].load_state_dict(torch.load(prefix+'model/stayup-exp' + str(i + 1) + '-1.ckpt'))\n",
    "\n",
    "        self.exp = exp_wrapper(self.basics[0], self.basics[1], self.basics[2], \n",
    "                               self.basics[3], self.basics[4], self.basics[5])\n",
    "        self.reg = pc_regressor()\n",
    "        self.main_layer = nn.Sequential(\n",
    "            nn.Linear(2, 1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "    # x: tensor\n",
    "    # size [num_epoch, (3 or 1) * 224 * 224 + 4]\n",
    "    # - x0: Tensor size[num_epoch, 3, 224, 224] or Tensor size[num_epoch, 1, 224, 224]\n",
    "    # - x1: Tensor size[num_epoch, 4]\n",
    "    def forward(self, x):\n",
    "        x0 = x[:, 0 : x.shape[-1] - 4]\n",
    "        x1 = x[:, x.shape[-1] - 4 : x.shape[-1]]\n",
    "        x0 = x0.view(x0.shape[0], -1, 224, 224).to(device)\n",
    "        x1 = x1.view(x1.shape[0], 4).to(device)\n",
    "        # print(self.exp(x0).shape)\n",
    "        # print(self.reg(x1).shape)\n",
    "        out = self.main_layer(torch.cat((torch.t(self.exp(x0)), self.reg(x1)), dim=-1)) * 8.0 + 1\n",
    "        return out\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# good stuff\n",
    "class ModelManager:\n",
    "    def __init__(self, model_name, model_path, train_path, test_path='', predict_path='', exp_index=0):\n",
    "        self.exp_index = exp_index\n",
    "        self.model_name = model_name\n",
    "        self.model_path = model_path\n",
    "        self.train_path = train_path\n",
    "        self.test_path = test_path\n",
    "        self.predict_path = predict_path\n",
    "\n",
    "        self.device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "        self.num_epochs = 32\n",
    "        self.learning_rate = 0.0005\n",
    "        self.batch_size = 16\n",
    "        if not self.exp_index == 0:\n",
    "            self.num_classes = 9\n",
    "        else:\n",
    "            self.num_classes = 1\n",
    "        self.print_len = 2\n",
    "        self.wd = 0\n",
    "\n",
    "        if not self.exp_index == 0:\n",
    "            self.criterion = nn.CrossEntropyLoss()\n",
    "        else:\n",
    "            self.criterion = nn.MSELoss()\n",
    "        self.transformer = transforms.Compose([\n",
    "            transforms.Resize((224, 224)),\n",
    "            transforms.ToTensor(),\n",
    "        #    transforms.Normalize(mean = (0.5,), std = (0.5,))\n",
    "        ])\n",
    "        self.get_model(init=True)\n",
    "        self.optimizer = torch.optim.Adamax(\n",
    "            params=self.model.parameters(),\n",
    "            lr=self.learning_rate,\n",
    "            weight_decay=self.wd\n",
    "        )\n",
    "    \n",
    "    def _get_data_loader(self, path, batch_size, predict=False, shuffle=True, cat=False, combined=False):\n",
    "        if not predict:\n",
    "            dataset = DispersionDataSet(path, self.exp_index, cat, combined, self.transformer)\n",
    "        else:\n",
    "            dataset = PredictDataSet(path, cat, combined, self.transformer)\n",
    "        return torch.utils.data.DataLoader(\n",
    "                    dataset=dataset,\n",
    "                    batch_size=batch_size,\n",
    "                    num_workers=4,\n",
    "                    shuffle=shuffle\n",
    "                )\n",
    "          \n",
    "    def get_model(self, init=False, train_again=False):\n",
    "        if init:\n",
    "            if 'resnet18' in self.model_name:\n",
    "                self.model = models.resnet18(pretrained=True)\n",
    "                self.model.conv1 = nn.Conv2d(1, 64, kernel_size=7, stride=2, padding=3, bias=False)\n",
    "                self.model.relu = nn.Sigmoid()\n",
    "            #    self.model.fc = nn.Linear(512, self.num_classes)\n",
    "            elif 'resnet50' in self.model_name:\n",
    "                self.model = models.resnet50(pretrained=True)\n",
    "                self.model.relu = nn.Sigmoid()\n",
    "                self.model.fc = nn.Linear(2048, self.num_classes)  \n",
    "            elif 'efficient' in self.model_name:\n",
    "                self.model = EfficientNet.from_pretrained('efficientnet-b0', num_classes=self.num_classes)\n",
    "            elif 'navienet' in self.model_name:\n",
    "                self.model = navienet(self.num_classes)\n",
    "            elif 'navie_regnet' in self.model_name:\n",
    "                self.model = navie_regnet()\n",
    "            elif 'stayup' in self.model_name:\n",
    "                res = models.resnet18(pretrained=True)\n",
    "                #res.conv1 = nn.Conv2d(1, 64, kernel_size=7, stride=2, padding=3, bias=False)\n",
    "                res.relu = nn.Sigmoid()\n",
    "                res.fc = nn.Linear(512, self.num_classes)\n",
    "                self.model = stayup_net(res.cuda())\n",
    "            elif 'combined_reg' in self.model_name:\n",
    "                self.model = combined_reg(plain_res=False)\n",
    "            else:\n",
    "                None\n",
    "        else:\n",
    "            if train_again or not os.path.exists(self.model_path):\n",
    "                if 'stayup' in self.model_name:\n",
    "                    data_loader = self._get_data_loader(self.train_path, batch_size=self.batch_size, shuffle=True, cat=True)\n",
    "                elif 'combined_reg' in self.model_name and not self.model.plain_res:\n",
    "                    data_loader = self._get_data_loader(self.train_path, batch_size=self.batch_size, shuffle=True, cat=True, combined=True)\n",
    "                else:\n",
    "                    data_loader = self._get_data_loader(self.train_path, batch_size=self.batch_size, shuffle=True)\n",
    "                self.train_it(data_loader, self.print_len, self.model_name)\n",
    "            else:\n",
    "                self.model.load_state_dict(torch.load(self.model_path))\n",
    "\n",
    "            if(train_again or not os.path.exists(self.model_path)):\n",
    "                torch.save(self.model.state_dict(), self.model_path)\n",
    "    \n",
    "    def train_it(self, train_data, print_len, log = ''):\n",
    "        self.model = self.model.to(self.device)\n",
    "        total_steps = len(train_data)\n",
    "        loss_list = []\n",
    "        for ep in range(self.num_epochs):\n",
    "            for i, (x, y) in enumerate(train_data):\n",
    "                if self.device.type == 'cuda':\n",
    "                    torch.cuda.empty_cache()\n",
    "\n",
    "                x = x.to(self.device)\n",
    "                y = y.to(self.device)\n",
    "                if 'Inception' in log:\n",
    "                    out, aux = self.model(x)\n",
    "                    loss1 = self.criterion(out, y)\n",
    "                    loss2 = self.criterion(aux, y)\n",
    "                    loss = loss1 + 0.4*loss2\n",
    "                else:\n",
    "                    out = self.model(x).squeeze()\n",
    "                    loss = self.criterion(out, y)\n",
    "                \n",
    "                self.optimizer.zero_grad()\n",
    "                loss.backward()\n",
    "                self.optimizer.step()\n",
    "                loss_list.append(loss.item())\n",
    "                if (i + 1) % print_len == 0:\n",
    "                    print(\n",
    "                        train_template.format(\n",
    "                            log, ep+1, self.num_epochs, i+1, total_steps, loss.item()\n",
    "                        ))\n",
    "        return loss_list\n",
    "\n",
    "    def test_it(self, log = ''):\n",
    "        self.model = self.model.to(self.device)\n",
    "        self.model.eval()\n",
    "        if 'combined_reg' in self.model_name:\n",
    "            test_data = self._get_data_loader(self.test_path, batch_size=1, shuffle=False, cat=True, combined=True)\n",
    "        elif 'stayup' in self.model_name:\n",
    "            test_data = self._get_data_loader(self.test_path, batch_size=1, shuffle=False, cat=True)\n",
    "        else:\n",
    "            test_data = self._get_data_loader(self.test_path, batch_size=1, shuffle=False)\n",
    "        predict_list = []\n",
    "        label_list = []\n",
    "        with torch.no_grad():\n",
    "            for x, y in test_data:\n",
    "                if self.device.type == 'cuda':\n",
    "                    torch.cuda.empty_cache()\n",
    "                x = x.to(self.device)\n",
    "                y = y.to(self.device)\n",
    "\n",
    "                out = self.model(x)\n",
    "                \n",
    "                if not self.exp_index == 0:\n",
    "                    pre = torch.argmax(out)\n",
    "                    predict_list.append(pre.cpu().item())\n",
    "                else:\n",
    "                    predict_list.append(out.data.cpu().item())\n",
    "                label_list.append(y.cpu().item())\n",
    "\n",
    "        print(test_template.format(log, len(predict_list), 100 * r2_score(label_list, predict_list)))\n",
    "        print('precision: {}'.format(np.sum(np.asarray(label_list) == np.asarray(predict_list)) / len(predict_list)))\n",
    "        print('label: {}'.format(label_list))\n",
    "        print('predict: {}'.format(predict_list))\n",
    "        print('r2dist: {}'.format(np.square(np.asarray(label_list) - np.asarray(predict_list))))\n",
    "\n",
    "    def predict_it(self):\n",
    "        self.model = self.model.to(self.device)\n",
    "        self.model.eval()\n",
    "        if 'combined_reg' in self.model_name:\n",
    "            predict_data = self._get_data_loader(self.test_path, batch_size=1, predict=True, shuffle=False, cat=True, combined=True)\n",
    "        elif 'stayup' in self.model_name:\n",
    "            predict_data = self._get_data_loader(self.test_path, batch_size=1, predict=True, shuffle=False, cat=True)\n",
    "        else:\n",
    "            predict_data = self._get_data_loader(self.test_path, batch_size=1, predict=True, shuffle=False)\n",
    "        predict_list = []\n",
    "        with torch.no_grad():\n",
    "            for x in predict_data:\n",
    "                if self.device.type == 'cuda':\n",
    "                    torch.cuda.empty_cache()\n",
    "                \n",
    "                x = x.to(self.device)\n",
    "                out = self.model(x)\n",
    "                if not self.exp_index == 0:\n",
    "                    pre = torch.argmax(out.data) + 1\n",
    "                    predict_list.append(pre.cpu().item())\n",
    "                else:\n",
    "                    predict_list.append(out.data.cpu().item())\n",
    "        \n",
    "        return predict_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for offline testing\n",
    "def get_mydataset(train_name, test_name, train_ratio=0.7, path=prefix + 'data/train_scores.csv', all=True):\n",
    "    train_df = pd.read_csv(path)\n",
    "    train_data_path = train_df['image']\n",
    "    if all:\n",
    "        train_labels = np.asarray([train_df['exp1'], train_df['exp2'], train_df['exp3'], train_df['exp4'], train_df['exp5'], train_df['exp6'], train_df['total_rating']])\n",
    "    else:\n",
    "        train_labels = np.asarray([train_df['total_rating']])\n",
    "    \n",
    "    mytrain_num = int(train_ratio * 197)\n",
    "    mytest_num = 197 - mytrain_num\n",
    "    if all:\n",
    "        mytrain_dict = {'image':[], 'exp1':[], 'exp2':[], 'exp3':[], 'exp4':[], 'exp5':[], 'exp6':[], 'total_rating':[]}\n",
    "        mytest_dict = {'image':[], 'exp1':[], 'exp2':[], 'exp3':[], 'exp4':[], 'exp5':[], 'exp6':[], 'total_rating':[]}\n",
    "    else:\n",
    "        mytrain_dict = {'image':[], 'total_rating':[]}\n",
    "        mytest_dict = {'image':[], 'total_rating':[]}\n",
    "    index = [x for x in range(197)]\n",
    "    random.shuffle(index)\n",
    "\n",
    "    for it in range(mytrain_num):\n",
    "        mytrain_dict['image'].append(train_data_path[it])\n",
    "        if all:\n",
    "            mytrain_dict['exp1'].append(train_labels[0][it])\n",
    "            mytrain_dict['exp2'].append(train_labels[1][it])\n",
    "            mytrain_dict['exp3'].append(train_labels[2][it])\n",
    "            mytrain_dict['exp4'].append(train_labels[3][it])\n",
    "            mytrain_dict['exp5'].append(train_labels[4][it])\n",
    "            mytrain_dict['exp6'].append(train_labels[5][it])\n",
    "            mytrain_dict['total_rating'].append(train_labels[6][it])\n",
    "        else:\n",
    "            mytrain_dict['total_rating'].append(train_labels[0][it])\n",
    "\n",
    "    for it in range(mytrain_num, 197):\n",
    "        mytest_dict['image'].append(train_data_path[it])\n",
    "        if all:\n",
    "            mytest_dict['exp1'].append(train_labels[0][it])\n",
    "            mytest_dict['exp2'].append(train_labels[1][it])\n",
    "            mytest_dict['exp3'].append(train_labels[2][it])\n",
    "            mytest_dict['exp4'].append(train_labels[3][it])\n",
    "            mytest_dict['exp5'].append(train_labels[4][it])\n",
    "            mytest_dict['exp6'].append(train_labels[5][it])\n",
    "            mytest_dict['total_rating'].append(train_labels[6][it])\n",
    "        else:\n",
    "            mytest_dict['total_rating'].append(train_labels[0][it])\n",
    "\n",
    "    pd.DataFrame(data=mytrain_dict).to_csv(prefix + 'data/' + train_name, index=False)\n",
    "    pd.DataFrame(data=mytest_dict).to_csv(prefix + 'data/' + test_name, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get_mydataset('mytrain_pca.csv', 'mytest_pca.csv', train_ratio=0.7, path=prefix + 'data/train_score_pca.csv', all=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp1_resnet18 = ModelManager(model_name='resnet18-exp1',\n",
    "                             model_path=prefix+'model/resnet18-exp1-814.ckpt',\n",
    "                             train_path=prefix+'data/train_scores.csv',\n",
    "                             test_path=prefix+'data/train_scores.csv', \n",
    "                             predict_path=prefix+'data/to_predict.csv', exp_index=1)\n",
    "exp1_resnet18.get_model(train_again=False)\n",
    "exp1_resnet18.test_it(log='test on test: ')\n",
    "pred_list_exp1_resnet18 = exp1_resnet18.predict_it()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp2_resnet18 = ModelManager(model_name='resnet18-exp2',\n",
    "                             model_path=prefix+'model/resnet18-exp2-814.ckpt',\n",
    "                             train_path=prefix+'data/train_scores.csv',\n",
    "                             test_path=prefix+'data/train_scores.csv',\n",
    "                             predict_path=prefix+'data/to_predict.csv', exp_index=2)\n",
    "exp2_resnet18.get_model(train_again=False)\n",
    "exp2_resnet18.test_it(log='test on test: ')\n",
    "pred_list_exp2_resnet18 = exp2_resnet18.predict_it()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp3_resnet18 = ModelManager(model_name='resnet18-exp3',\n",
    "                             model_path=prefix+'model/resnet18-exp3-814.ckpt',\n",
    "                             train_path=prefix+'data/train_scores.csv',\n",
    "                             test_path=prefix+'data/train_scores.csv',\n",
    "                             predict_path=prefix+'data/to_predict.csv', exp_index=3)\n",
    "exp3_resnet18.get_model(train_again=False)\n",
    "exp3_resnet18.test_it(log='test on test: ')\n",
    "pred_list_exp3_resnet18 = exp3_resnet18.predict_it()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp4_resnet18 = ModelManager(model_name='resnet18-exp4',\n",
    "                             model_path=prefix+'model/resnet18-exp4-814.ckpt',\n",
    "                             train_path=prefix+'data/train_scores.csv',\n",
    "                             test_path=prefix+'data/train_scores.csv',\n",
    "                             predict_path=prefix+'data/to_predict.csv', exp_index=4)\n",
    "exp4_resnet18.get_model(train_again=False)\n",
    "exp4_resnet18.test_it(log='test on test: ')\n",
    "pred_list_exp4_resnet18 = exp4_resnet18.predict_it()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp5_resnet18 = ModelManager(model_name='resnet18-exp5',\n",
    "                             model_path=prefix+'model/resnet18-exp5-814.ckpt',\n",
    "                             train_path=prefix+'data/train_scores.csv',\n",
    "                             test_path=prefix+'data/train_scores.csv',\n",
    "                             predict_path=prefix+'data/to_predict.csv', exp_index=5)\n",
    "exp5_resnet18.get_model(train_again=False)\n",
    "exp5_resnet18.test_it(log='test on test: ')\n",
    "pred_list_exp5_resnet18 = exp5_resnet18.predict_it()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp6_resnet18 = ModelManager(model_name='resnet18-exp6',\n",
    "                             model_path=prefix+'model/resnet18-exp6-814.ckpt',\n",
    "                             train_path=prefix+'data/train_scores.csv',\n",
    "                             test_path=prefix+'data/train_scores.csv',\n",
    "                             predict_path=prefix+'data/to_predict.csv', exp_index=6)\n",
    "exp6_resnet18.get_model(train_again=False)\n",
    "exp6_resnet18.test_it(log='test on test: ')\n",
    "pred_list_exp6_resnet18 = exp6_resnet18.predict_it()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp1_stayup = ModelManager(model_name='stayup-exp1',\n",
    "                          model_path=prefix+'model/stayup-exp1-1.ckpt',\n",
    "                          train_path=prefix+'data/train_scores_bigger.csv',\n",
    "                          test_path=prefix+'data/train_scores_bigger.csv',\n",
    "                          predict_path=prefix+'data/to_predict.csv', exp_index=1)\n",
    "exp1_stayup.get_model(train_again=False)\n",
    "exp1_stayup.test_it(log='test on test: ')\n",
    "pred_list_exp1_stayup = exp1_stayup.predict_it()\n",
    "\n",
    "exp2_stayup = ModelManager(model_name='stayup-exp2',\n",
    "                          model_path=prefix+'model/stayup-exp2-1.ckpt',\n",
    "                          train_path=prefix+'data/train_scores_bigger.csv',\n",
    "                          test_path=prefix+'data/train_scores_bigger.csv',\n",
    "                          predict_path=prefix+'data/to_predict.csv', exp_index=2)\n",
    "exp2_stayup.get_model(train_again=False)\n",
    "exp2_stayup.test_it(log='test on test: ')\n",
    "pred_list_exp2_stayup = exp2_stayup.predict_it()\n",
    "\n",
    "exp3_stayup = ModelManager(model_name='stayup-exp3',\n",
    "                          model_path=prefix+'model/stayup-exp3-1.ckpt',\n",
    "                          train_path=prefix+'data/train_scores_bigger.csv',\n",
    "                          test_path=prefix+'data/train_scores_bigger.csv',\n",
    "                          predict_path=prefix+'data/to_predict.csv', exp_index=3)\n",
    "exp3_stayup.get_model(train_again=False)\n",
    "exp3_stayup.test_it(log='test on test: ')\n",
    "pred_list_exp3_stayup = exp3_stayup.predict_it()\n",
    "\n",
    "exp4_stayup = ModelManager(model_name='stayup-exp4',\n",
    "                          model_path=prefix+'model/stayup-exp4-1.ckpt',\n",
    "                          train_path=prefix+'data/train_scores_bigger.csv',\n",
    "                          test_path=prefix+'data/train_scores_bigger.csv',\n",
    "                          predict_path=prefix+'data/to_predict.csv', exp_index=4)\n",
    "exp4_stayup.get_model(train_again=False)\n",
    "exp4_stayup.test_it(log='test on test: ')\n",
    "pred_list_exp4_stayup = exp4_stayup.predict_it()\n",
    "\n",
    "exp5_stayup = ModelManager(model_name='stayup-exp5',\n",
    "                          model_path=prefix+'model/stayup-exp5-1.ckpt',\n",
    "                          train_path=prefix+'data/train_scores_bigger.csv',\n",
    "                          test_path=prefix+'data/train_scores_bigger.csv',\n",
    "                          predict_path=prefix+'data/to_predict.csv', exp_index=5)\n",
    "exp5_stayup.get_model(train_again=False)\n",
    "exp5_stayup.test_it(log='test on test: ')\n",
    "pred_list_exp5_stayup = exp5_stayup.predict_it()\n",
    "\n",
    "exp6_stayup = ModelManager(model_name='stayup-exp6',\n",
    "                          model_path=prefix+'model/stayup-exp6-1.ckpt',\n",
    "                          train_path=prefix+'data/train_scores_bigger.csv',\n",
    "                          test_path=prefix+'data/train_scores_bigger.csv',\n",
    "                          predict_path=prefix+'data/to_predict.csv', exp_index=6)\n",
    "exp6_stayup.get_model(train_again=False)\n",
    "exp6_stayup.test_it(log='test on test: ')\n",
    "pred_list_exp6_stayup = exp6_stayup.predict_it()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write ans to *.csv\n",
    "def ans2csv(pred1, pred2, pred3, pred4, pred5, pred6, pred_path, result_path, all=False, weigh=False):\n",
    "    if not weigh:\n",
    "        pred_avg = (np.asarray(pred1) + np.asarray(pred2) + np.asarray(pred3) \n",
    "                 + np.asarray(pred4) + np.asarray(pred5) + np.asarray(pred6)) / 6.0\n",
    "    else:\n",
    "        pred_avg = (np.asarray(pred1)*weight[0] + np.asarray(pred2)*weight[1] + np.asarray(pred3)*weight[2] \n",
    "                 + np.asarray(pred4)*weight[3] + np.asarray(pred5)*weight[4] + np.asarray(pred6)*weight[5])\n",
    "    if not all:\n",
    "        pred_dict = {'image':[], 'total_rating':[]}\n",
    "\n",
    "        for it, id in enumerate(pd.read_csv(pred_path)['image']):\n",
    "            pred_dict['image'].append(id)\n",
    "            pred_dict['total_rating'].append(round(pred_avg[it], 1))\n",
    "\n",
    "        pd.DataFrame(data=pred_dict).to_csv(result_path, index=False)\n",
    "    else:\n",
    "        pred_dict = {'image':[], 'exp1':[], 'exp2':[], 'exp3':[], \n",
    "                    'exp4':[], 'exp5':[], 'exp6':[], 'total_rating':[]}\n",
    "        for it, id in enumerate(pd.read_csv(pred_path)['image']):\n",
    "            pred_dict['image'].append(id)\n",
    "            pred_dict['exp1'].append(round(pred1[it], 1))\n",
    "            pred_dict['exp2'].append(round(pred2[it], 1))\n",
    "            pred_dict['exp3'].append(round(pred3[it], 1))\n",
    "            pred_dict['exp4'].append(round(pred4[it], 1))\n",
    "            pred_dict['exp5'].append(round(pred5[it], 1))\n",
    "            pred_dict['exp6'].append(round(pred6[it], 1))\n",
    "            pred_dict['total_rating'].append(round(pred_avg[it], 1))\n",
    "\n",
    "        pd.DataFrame(data=pred_dict).to_csv(result_path, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "ans2csv(pred_list_exp1_resnet18, pred_list_exp2_resnet18, pred_list_exp3_resnet18,\n",
    "        pred_list_exp4_resnet18, pred_list_exp5_resnet18, pred_list_exp6_resnet18,\n",
    "        pred_path=prefix+'data/to_predict.csv',\n",
    "        result_path=prefix + 'result/team6submission_resnet18_bs16_lr0.0005_withoutnorm_32epochs_sigmoid_ncori_avg.csv',\n",
    "        all=False, weigh=False)\n",
    "'''\n",
    "ans2csv(pred_list_exp1_stayup, pred_list_exp2_stayup, pred_list_exp3_stayup,\n",
    "        pred_list_exp4_stayup, pred_list_exp5_stayup, pred_list_exp6_stayup,\n",
    "        pred_path=prefix+'data/to_predict.csv',\n",
    "        result_path=prefix + 'result/team6submission_stayup_bs16_lr0.0005_withoutnorm_32epochs_sigmoid_nc9_avg_B.csv',\n",
    "        all=False, weigh=False)\n",
    "'''\n",
    "ans2csv(pred_list_exp1_resnet18, pred_list_exp2_resnet18, pred_list_exp3_resnet18,\n",
    "        pred_list_exp4_resnet18, pred_list_exp5_resnet18, pred_list_exp6_resnet18,\n",
    "        pred_path=prefix+'data/to_predict.csv',\n",
    "        result_path=prefix + 'result/predict_scores_resnet18_bs16_lr0.0005_withoutnorm_64epochs_nc9.csv',\n",
    "        all=True)\n",
    "'''\n"
   ]
  }
 ],
 "metadata": {
  "file_extension": ".py",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
